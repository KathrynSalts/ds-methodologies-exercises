{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using case.csv & dept.csv: \n",
    "1. read into spark environment (df_case, df_dept) \n",
    "2. write df_case and df_dept back to disk into their own directories (my_cases and my_depts) \n",
    "3. Write df_case and df_dept to parquet files (my_cases_parquet and my_depts_parquet) \n",
    "4. Read your parquet files back into your spark environment. \n",
    "5. Read case.csv and dept.csv into a pandas dataframe. (cases_pdf, depts_pdf) \n",
    "6. Convert the pandas dataframes into spark dataframes (cases_sdf, depts_sdf) \n",
    "7. Convert the spark dataframes back into pandas dataframes. (cases_pdf1, depts_pdf1) \n",
    "8. Write the spark dataframes (cases_sdf, depts_sdf) to Hive tables. \n",
    "9. Explore the Hive database/tables you have created using the methods in the lesson. \n",
    "10. Read from the tables into two spark dataframes (cases_sdf, depts_sdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read into environment <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "spark = pyspark.sql.SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case = (spark.read\n",
    " .option('header', True)\n",
    " .format('csv')\n",
    " .load('./sa311/case.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(case_id='1014127332', case_opened_date='1/1/18 0:42', case_closed_date='1/1/18 12:29', SLA_due_date='9/26/20 0:42', case_late='NO', num_days_late='-998.5087616000001', case_closed='YES', dept_division='Field Operations', service_request_type='Stray Animal', SLA_days='999.0', case_status='Closed', source_id='svcCRMLS', request_address='2315  EL PASO ST, San Antonio, 78207', council_district='5')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_case.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dept = (spark.read\n",
    " .option('header', True)\n",
    " .format('csv')\n",
    " .load('./sa311/dept.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(dept_division='311 Call Center', dept_name='Customer Service', standardized_dept_name='Customer Service', dept_subject_to_SLA='YES')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dept.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write back into their own directories <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case.write.format('csv').mode(\"overwrite\").\\\n",
    "    option(\"header\",\"true\").save(\"sa311/df_case\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dept.write.format('csv').mode(\"overwrite\").\\\n",
    "    option(\"header\",\"true\").save(\"sa311/df_dept\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write to parquet files <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case.write.format('parquet').mode('overwrite').\\\n",
    "    option('header','true').save('sa311/df_case_parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dept.write.format('parquet').mode('overwrite').\\\n",
    "    option('header','true').save('sa311/df_dept_parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read parquet back into spark <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_case = spark.read.format('parquet').\\\n",
    "    option(\"header\", True).\\\n",
    "    option(\"inferSchema\", True).\\\n",
    "    load(\"sa311/df_case_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dept = spark.read.format('parquet').\\\n",
    "    option(\"header\", True).\\\n",
    "    option(\"inferSchema\", True).\\\n",
    "    load(\"sa311/df_dept_parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read csv files to pandas df <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>case_id</th>\n",
       "      <th>case_opened_date</th>\n",
       "      <th>case_closed_date</th>\n",
       "      <th>SLA_due_date</th>\n",
       "      <th>case_late</th>\n",
       "      <th>num_days_late</th>\n",
       "      <th>case_closed</th>\n",
       "      <th>dept_division</th>\n",
       "      <th>service_request_type</th>\n",
       "      <th>SLA_days</th>\n",
       "      <th>case_status</th>\n",
       "      <th>source_id</th>\n",
       "      <th>request_address</th>\n",
       "      <th>council_district</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1014127332</td>\n",
       "      <td>1/1/18 0:42</td>\n",
       "      <td>1/1/18 12:29</td>\n",
       "      <td>9/26/20 0:42</td>\n",
       "      <td>NO</td>\n",
       "      <td>-998.508762</td>\n",
       "      <td>YES</td>\n",
       "      <td>Field Operations</td>\n",
       "      <td>Stray Animal</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMLS</td>\n",
       "      <td>2315  EL PASO ST, San Antonio, 78207</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1014127333</td>\n",
       "      <td>1/1/18 0:46</td>\n",
       "      <td>1/3/18 8:11</td>\n",
       "      <td>1/5/18 8:30</td>\n",
       "      <td>NO</td>\n",
       "      <td>-2.012604</td>\n",
       "      <td>YES</td>\n",
       "      <td>Storm Water</td>\n",
       "      <td>Removal Of Obstruction</td>\n",
       "      <td>4.322222</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>2215  GOLIAD RD, San Antonio, 78223</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1014127334</td>\n",
       "      <td>1/1/18 0:48</td>\n",
       "      <td>1/2/18 7:57</td>\n",
       "      <td>1/5/18 8:30</td>\n",
       "      <td>NO</td>\n",
       "      <td>-3.022338</td>\n",
       "      <td>YES</td>\n",
       "      <td>Storm Water</td>\n",
       "      <td>Removal Of Obstruction</td>\n",
       "      <td>4.320729</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>102  PALFREY ST W, San Antonio, 78223</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1014127335</td>\n",
       "      <td>1/1/18 1:29</td>\n",
       "      <td>1/2/18 8:13</td>\n",
       "      <td>1/17/18 8:30</td>\n",
       "      <td>NO</td>\n",
       "      <td>-15.011481</td>\n",
       "      <td>YES</td>\n",
       "      <td>Code Enforcement</td>\n",
       "      <td>Front Or Side Yard Parking</td>\n",
       "      <td>16.291887</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>114  LA GARDE ST, San Antonio, 78223</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1014127336</td>\n",
       "      <td>1/1/18 1:34</td>\n",
       "      <td>1/1/18 13:29</td>\n",
       "      <td>1/1/18 4:34</td>\n",
       "      <td>YES</td>\n",
       "      <td>0.372164</td>\n",
       "      <td>YES</td>\n",
       "      <td>Field Operations</td>\n",
       "      <td>Animal Cruelty(Critical)</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>Closed</td>\n",
       "      <td>svcCRMSS</td>\n",
       "      <td>734  CLEARVIEW DR, San Antonio, 78228</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      case_id case_opened_date case_closed_date  SLA_due_date case_late  \\\n",
       "0  1014127332      1/1/18 0:42     1/1/18 12:29  9/26/20 0:42        NO   \n",
       "1  1014127333      1/1/18 0:46      1/3/18 8:11   1/5/18 8:30        NO   \n",
       "2  1014127334      1/1/18 0:48      1/2/18 7:57   1/5/18 8:30        NO   \n",
       "3  1014127335      1/1/18 1:29      1/2/18 8:13  1/17/18 8:30        NO   \n",
       "4  1014127336      1/1/18 1:34     1/1/18 13:29   1/1/18 4:34       YES   \n",
       "\n",
       "   num_days_late case_closed     dept_division        service_request_type  \\\n",
       "0    -998.508762         YES  Field Operations                Stray Animal   \n",
       "1      -2.012604         YES       Storm Water      Removal Of Obstruction   \n",
       "2      -3.022338         YES       Storm Water      Removal Of Obstruction   \n",
       "3     -15.011481         YES  Code Enforcement  Front Or Side Yard Parking   \n",
       "4       0.372164         YES  Field Operations    Animal Cruelty(Critical)   \n",
       "\n",
       "     SLA_days case_status source_id                        request_address  \\\n",
       "0  999.000000      Closed  svcCRMLS   2315  EL PASO ST, San Antonio, 78207   \n",
       "1    4.322222      Closed  svcCRMSS    2215  GOLIAD RD, San Antonio, 78223   \n",
       "2    4.320729      Closed  svcCRMSS  102  PALFREY ST W, San Antonio, 78223   \n",
       "3   16.291887      Closed  svcCRMSS   114  LA GARDE ST, San Antonio, 78223   \n",
       "4    0.125000      Closed  svcCRMSS  734  CLEARVIEW DR, San Antonio, 78228   \n",
       "\n",
       "   council_district  \n",
       "0                 5  \n",
       "1                 3  \n",
       "2                 3  \n",
       "3                 3  \n",
       "4                 7  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "cases_pdf= pd.read_csv(\"sa311/case.csv\", sep=\",\")\n",
    "cases_pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dept_division</th>\n",
       "      <th>dept_name</th>\n",
       "      <th>standardized_dept_name</th>\n",
       "      <th>dept_subject_to_SLA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>311 Call Center</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>Customer Service</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Brush</td>\n",
       "      <td>Solid Waste Management</td>\n",
       "      <td>Solid Waste</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Clean and Green</td>\n",
       "      <td>Parks and Recreation</td>\n",
       "      <td>Parks &amp; Recreation</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clean and Green Natural Areas</td>\n",
       "      <td>Parks and Recreation</td>\n",
       "      <td>Parks &amp; Recreation</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Code Enforcement</td>\n",
       "      <td>Code Enforcement Services</td>\n",
       "      <td>DSD/Code Enforcement</td>\n",
       "      <td>YES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   dept_division                  dept_name  \\\n",
       "0                311 Call Center           Customer Service   \n",
       "1                          Brush     Solid Waste Management   \n",
       "2                Clean and Green       Parks and Recreation   \n",
       "3  Clean and Green Natural Areas       Parks and Recreation   \n",
       "4               Code Enforcement  Code Enforcement Services   \n",
       "\n",
       "  standardized_dept_name dept_subject_to_SLA  \n",
       "0       Customer Service                 YES  \n",
       "1            Solid Waste                 YES  \n",
       "2     Parks & Recreation                 YES  \n",
       "3     Parks & Recreation                 YES  \n",
       "4   DSD/Code Enforcement                 YES  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depts_pdf = pd.read_csv(\"sa311/dept.csv\", sep=\",\")\n",
    "depts_pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandas to spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyspark.sql.types as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# schema = T.StructType([T.StructField('x', T.StringType())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convert spark df to Hive tables <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid   # Create unique table name\n",
    "table_name = \"df_\" + str(uuid.uuid4().hex)  \n",
    "df_case.write.saveAsTable(table_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name2 = \"df_\" + str(uuid.uuid4().hex)  \n",
    "df_dept.write.saveAsTable(table_name2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "explore Hive tables <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|             case_id|   string|   null|\n",
      "|    case_opened_date|   string|   null|\n",
      "|    case_closed_date|   string|   null|\n",
      "|        SLA_due_date|   string|   null|\n",
      "|           case_late|   string|   null|\n",
      "|       num_days_late|   string|   null|\n",
      "|         case_closed|   string|   null|\n",
      "|       dept_division|   string|   null|\n",
      "|service_request_type|   string|   null|\n",
      "|            SLA_days|   string|   null|\n",
      "|         case_status|   string|   null|\n",
      "|           source_id|   string|   null|\n",
      "|     request_address|   string|   null|\n",
      "|    council_district|   string|   null|\n",
      "+--------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query1 = \"DESCRIBE %s\" % table_name\n",
    "hive_cases = spark.sql(query1)\n",
    "hive_cases.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|       dept_division|   string|   null|\n",
      "|           dept_name|   string|   null|\n",
      "|standardized_dept...|   string|   null|\n",
      "| dept_subject_to_SLA|   string|   null|\n",
      "+--------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query2 = \"DESCRIBE %s\" % table_name2\n",
    "hive_depts = spark.sql(query2)\n",
    "hive_depts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read Hive tables to spark df <<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+\n",
      "|databaseName|\n",
      "+------------+\n",
      "|     default|\n",
      "+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SHOW DATABASES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+-----------+\n",
      "|database|           tableName|isTemporary|\n",
      "+--------+--------------------+-----------+\n",
      "| default|df_52994663b53044...|      false|\n",
      "| default|df_bcd53088db2d44...|      false|\n",
      "+--------+--------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"USE default\")\n",
    "spark.sql(\"SHOW TABLES\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+-------+\n",
      "|            col_name|data_type|comment|\n",
      "+--------------------+---------+-------+\n",
      "|             case_id|   string|   null|\n",
      "|    case_opened_date|   string|   null|\n",
      "|    case_closed_date|   string|   null|\n",
      "|        SLA_due_date|   string|   null|\n",
      "|           case_late|   string|   null|\n",
      "|       num_days_late|   string|   null|\n",
      "|         case_closed|   string|   null|\n",
      "|       dept_division|   string|   null|\n",
      "|service_request_type|   string|   null|\n",
      "|            SLA_days|   string|   null|\n",
      "|         case_status|   string|   null|\n",
      "|           source_id|   string|   null|\n",
      "|     request_address|   string|   null|\n",
      "|    council_district|   string|   null|\n",
      "+--------------------+---------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"DESCRIBE {table_name}\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+----------------+-------------+---------+------------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+\n",
      "|   case_id|case_opened_date|case_closed_date| SLA_due_date|case_late|     num_days_late|case_closed|   dept_division|service_request_type|   SLA_days|case_status|source_id|     request_address|council_district|\n",
      "+----------+----------------+----------------+-------------+---------+------------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+\n",
      "|1014551581|   5/28/18 13:14|   5/28/18 14:23|5/28/18 16:14|       NO|      -0.077511574|        YES|Field Operations|     Officer Standby|      0.125|     Closed|  NO10960|7003  RAVENSDALE,...|               6|\n",
      "|1014551583|   5/28/18 13:15|   5/29/18 14:38|  6/1/18 8:30|       NO|      -2.743912037|        YES|Waste Collection|           No Pickup|   3.801875|     Closed|   138793|1906  MOSSY CREEK...|               4|\n",
      "|1014551584|   5/28/18 13:16|   5/29/18 14:31|  6/5/18 8:30|       NO|      -6.749131944|        YES|Waste Collection|    Lost/Stolen Cart|7.801087963|     Closed|   142989|103  SPRINGWOOD L...|               1|\n",
      "|1014551586|   5/28/18 13:16|   5/29/18 12:13|  6/5/18 8:30|       NO|-6.844756943999999|        YES|Waste Collection|         Cart PickUp|7.800763889|     Closed|  me05816|6623  CHASETHORN ...|               8|\n",
      "|1014551589|   5/28/18 13:17|   7/10/18 11:42|  8/1/18 8:30|       NO|      -21.86633102|        YES|Code Enforcement|Alley-Way Mainten...|64.80019676|     Closed|  DS15677|1629  MULBERRY AV...|               1|\n",
      "|1014551594|   5/28/18 13:19|   5/29/18 14:38|  6/5/18 8:30|       NO|      -6.743796296|        YES|Waste Collection|Cart Exchange Req...|7.799178241|     Closed|   140508|315  WARD AVE, Sa...|               3|\n",
      "|1014551595|   5/28/18 13:19|   5/31/18 10:15| 6/2/18 13:19|       NO|      -2.127835648|        YES|Field Operations|Aggressive Animal...|        5.0|     Closed|   138793|1300  TRINITY N, ...|               1|\n",
      "|1014551604|   5/28/18 13:21|    6/5/18 13:40|  6/7/18 8:30|       NO|      -1.784513889|        YES|           Brush|Brush - Out of Cy...|9.797233796|     Closed|   140436|5102  MEADOW COVE...|               6|\n",
      "|1014551606|   5/28/18 13:22|   5/30/18 13:21|  6/1/18 8:30|       NO|      -1.797847222|        YES|Waste Collection|           No Pickup|3.797048611|     Closed|  cc17850|312  TRAIL, San A...|               1|\n",
      "|1014551610|   5/28/18 13:24|     6/5/18 8:37| 10/4/18 8:30|       NO|       -120.994456|        YES|Code Enforcement|Minimum Housing-O...|128.7952894|     Closed|  DS15677|310  KASHMUIR PLA...|               3|\n",
      "+----------+----------------+----------------+-------------+---------+------------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(f\"SELECT * FROM {table_name} LIMIT 10\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+----------------+----------------+-------------+---------+------------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+\n",
      "|   case_id|case_opened_date|case_closed_date| SLA_due_date|case_late|     num_days_late|case_closed|   dept_division|service_request_type|   SLA_days|case_status|source_id|     request_address|council_district|\n",
      "+----------+----------------+----------------+-------------+---------+------------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+\n",
      "|1014551581|   5/28/18 13:14|   5/28/18 14:23|5/28/18 16:14|       NO|      -0.077511574|        YES|Field Operations|     Officer Standby|      0.125|     Closed|  NO10960|7003  RAVENSDALE,...|               6|\n",
      "|1014551583|   5/28/18 13:15|   5/29/18 14:38|  6/1/18 8:30|       NO|      -2.743912037|        YES|Waste Collection|           No Pickup|   3.801875|     Closed|   138793|1906  MOSSY CREEK...|               4|\n",
      "|1014551584|   5/28/18 13:16|   5/29/18 14:31|  6/5/18 8:30|       NO|      -6.749131944|        YES|Waste Collection|    Lost/Stolen Cart|7.801087963|     Closed|   142989|103  SPRINGWOOD L...|               1|\n",
      "|1014551586|   5/28/18 13:16|   5/29/18 12:13|  6/5/18 8:30|       NO|-6.844756943999999|        YES|Waste Collection|         Cart PickUp|7.800763889|     Closed|  me05816|6623  CHASETHORN ...|               8|\n",
      "|1014551589|   5/28/18 13:17|   7/10/18 11:42|  8/1/18 8:30|       NO|      -21.86633102|        YES|Code Enforcement|Alley-Way Mainten...|64.80019676|     Closed|  DS15677|1629  MULBERRY AV...|               1|\n",
      "+----------+----------------+----------------+-------------+---------+------------------+-----------+----------------+--------------------+-----------+-----------+---------+--------------------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cases_sdf = spark.sql(f\"SELECT * FROM {table_name}\")\n",
    "cases_sdf.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
